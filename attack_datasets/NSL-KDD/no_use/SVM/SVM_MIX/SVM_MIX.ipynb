{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:48.535599700Z",
     "start_time": "2023-12-24T18:14:48.374560600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "file_path_train = r\"D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\KDDTrain+.txt\"\n",
    "file_path_test = r\"D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\KDDTest+.txt\"\n",
    "# 定义列名\n",
    "data_columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "                \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "                \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "                \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "                \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "                \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "                \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "                \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "                \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "                \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\", \"difficulty\"]\n",
    "# 加载数据\n",
    "train_data = pd.read_csv(file_path_train, header=None, names=data_columns)\n",
    "test_data = pd.read_csv(file_path_test, header=None, names=data_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:48.788545700Z",
     "start_time": "2023-12-24T18:14:48.535599700Z"
    }
   },
   "id": "3c211b6f2917f4e0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "attack_mapping = {}\n",
    "with open(r'D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\attack_name',\n",
    "          'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(' ')\n",
    "        if len(parts) == 2:\n",
    "            attack, category = parts\n",
    "            attack_mapping[attack] = category\n",
    "# 然后像之前那样使用这个映射字典\n",
    "train_data['label'] = train_data['label'].map(attack_mapping)\n",
    "test_data['label'] = test_data['label'].map(attack_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:48.804102700Z",
     "start_time": "2023-12-24T18:14:48.788545700Z"
    }
   },
   "id": "7cbbbc0a025f064c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label is Counter({'normal': 67343, 'dos': 45927, 'probe': 11656, 'r2l': 995, 'u2r': 52})\n",
      "test_label is Counter({'normal': 9711, 'dos': 7636, 'r2l': 2576, 'probe': 2421, 'u2r': 200})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(f'train_label is {Counter(train_data[\"label\"])}')\n",
    "print(f'test_label is {Counter(test_data[\"label\"])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:48.867221Z",
     "start_time": "2023-12-24T18:14:48.804102700Z"
    }
   },
   "id": "f7f0987afb40544b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 合并数据集\n",
    "combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# 提取特征和标签\n",
    "X = combined_data.drop('label', axis=1)  # 假设 'label' 列是目标变量\n",
    "X = X.drop('difficulty', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "# 分层抽样划分训练集和测试集\n",
    "train_data, test_data, label_train, label_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.010194500Z",
     "start_time": "2023-12-24T18:14:48.836068200Z"
    }
   },
   "id": "fb6f123586bc40a1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中各类别的数量：\n",
      " label\n",
      "normal    53937\n",
      "dos       37494\n",
      "probe      9854\n",
      "r2l        2500\n",
      "u2r         176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集中各类别的数量：\n",
      " label\n",
      "normal    23117\n",
      "dos       16069\n",
      "probe      4223\n",
      "r2l        1071\n",
      "u2r          76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 统计训练集中每个类别的数量\n",
    "train_label_counts = label_train.value_counts()\n",
    "# 统计测试集中每个类别的数量\n",
    "test_label_counts = label_test.value_counts()\n",
    "# 打印结果\n",
    "print(\"训练集中各类别的数量：\\n\", train_label_counts)\n",
    "print(\"\\n测试集中各类别的数量：\\n\", test_label_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.025956100Z",
     "start_time": "2023-12-24T18:14:49.010194500Z"
    }
   },
   "id": "dcde0d65204fe1c0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service type only exist in train_dataset: {'http_2784', 'tftp_u'}\n",
      "protocol type only exist in train_dataset: set()\n",
      "flag type only exist in train_dataset: set()\n",
      "-------------------------------------------------------\n",
      "service type only exist in test_dataset: set()\n",
      "protocol type only exist in test_dataset: set()\n",
      "flag type only exist in test_dataset: set()\n"
     ]
    }
   ],
   "source": [
    "# 获取训练集和测试集中的 'service' 列\n",
    "service_train = train_data['service']\n",
    "service_test = test_data['service']\n",
    "\n",
    "protocol_type_train = train_data['protocol_type']\n",
    "protocol_type_test = test_data['protocol_type']\n",
    "\n",
    "flag_train = train_data['flag']\n",
    "flag_test = test_data['flag']\n",
    "\n",
    "# 找出只在训练集中出现的 service 类型\n",
    "unique_service = set(service_train) - set(service_test)\n",
    "unique_protocol_type = set(protocol_type_train) - set(protocol_type_test)\n",
    "unique_flag = set(flag_train) - set(flag_test)\n",
    "\n",
    "test_unique_service = set(service_test) - set(service_train)\n",
    "test_unique_protocol_type = set(protocol_type_test) - set(protocol_type_train)\n",
    "test_unique_flag = set(flag_test) - set(flag_train)\n",
    "\n",
    "# 输出结果\n",
    "print(\"service type only exist in train_dataset:\", unique_service)\n",
    "print(\"protocol type only exist in train_dataset:\", unique_protocol_type)\n",
    "print(\"flag type only exist in train_dataset:\", unique_flag)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"service type only exist in test_dataset:\", test_unique_service)\n",
    "print(\"protocol type only exist in test_dataset:\", test_unique_protocol_type)\n",
    "print(\"flag type only exist in test_dataset:\", test_unique_flag)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.073525600Z",
     "start_time": "2023-12-24T18:14:49.025956100Z"
    }
   },
   "id": "d2f65655f746f0d2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences for service 'http_2784': 1\n",
      "Number of occurrences for service 'tftp_u': 4\n"
     ]
    }
   ],
   "source": [
    "# 定义要检查的服务类型列表\n",
    "services_to_check = ['http_2784', 'tftp_u']\n",
    "\n",
    "# 对每种服务类型进行计数\n",
    "for service in services_to_check:\n",
    "    count = (train_data['service'] == service).sum()\n",
    "    print(f\"Number of occurrences for service '{service}': {count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.089252200Z",
     "start_time": "2023-12-24T18:14:49.073525600Z"
    }
   },
   "id": "3249d13e35612923"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 找出只在训练集中出现的 service 类型\n",
    "unique_service_train = set(train_data['service']) - set(test_data['service'])\n",
    "\n",
    "# 删除训练集中存在但测试集中不存在的 service 类型的行\n",
    "indices_to_remove = train_data[train_data['service'].isin(unique_service_train)].index\n",
    "train_data = train_data.drop(indices_to_remove)\n",
    "label_train = label_train.drop(indices_to_remove)\n",
    "# 现在 train_data 和 label_train 是同步的"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.139322300Z",
     "start_time": "2023-12-24T18:14:49.089252200Z"
    }
   },
   "id": "4e36fa46419cfb04"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中各类别的数量：\n",
      " label\n",
      "normal    53932\n",
      "dos       37494\n",
      "probe      9853\n",
      "r2l        2500\n",
      "u2r         176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集中各类别的数量：\n",
      " label\n",
      "normal    23117\n",
      "dos       16069\n",
      "probe      4223\n",
      "r2l        1071\n",
      "u2r          76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 统计训练集中每个类别的数量\n",
    "train_label_counts = label_train.value_counts()\n",
    "# 统计测试集中每个类别的数量\n",
    "test_label_counts = label_test.value_counts()\n",
    "# 打印结果\n",
    "print(\"训练集中各类别的数量：\\n\", train_label_counts)\n",
    "print(\"\\n测试集中各类别的数量：\\n\", test_label_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.155081600Z",
     "start_time": "2023-12-24T18:14:49.139322300Z"
    }
   },
   "id": "d647dc14fa62df24"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service type only exist in train_dataset: set()\n",
      "-------------------------------------------------------\n",
      "service type only exist in test_dataset: set()\n"
     ]
    }
   ],
   "source": [
    "# 找出只在训练集中出现的 service 类型\n",
    "unique_service = set(train_data) - set(test_data)\n",
    "test_unique_service = set(test_data) - set(train_data)\n",
    "# 输出结果\n",
    "print(\"service type only exist in train_dataset:\", unique_service)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"service type only exist in test_dataset:\", test_unique_service)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.201939Z",
     "start_time": "2023-12-24T18:14:49.155081600Z"
    }
   },
   "id": "a4d93bb3707c4297"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 初始化LabelEncoder\n",
    "le_protocol_type = preprocessing.LabelEncoder()\n",
    "le_service = preprocessing.LabelEncoder()\n",
    "le_flag = preprocessing.LabelEncoder()\n",
    "le_labels = preprocessing.LabelEncoder()\n",
    "\n",
    "# 对训练集进行标签编码\n",
    "train_data['protocol_type'] = le_protocol_type.fit_transform(train_data['protocol_type'])\n",
    "train_data['service'] = le_service.fit_transform(train_data['service'])\n",
    "train_data['flag'] = le_flag.fit_transform(train_data['flag'])\n",
    "label_train = le_labels.fit_transform(label_train) + 1\n",
    "\n",
    "# 使用相同的编码器对测试集进行标签编码\n",
    "test_data['protocol_type'] = le_protocol_type.transform(test_data['protocol_type'])\n",
    "test_data['service'] = le_service.transform(test_data['service'])\n",
    "test_data['flag'] = le_flag.transform(test_data['flag'])\n",
    "label_test = le_labels.transform(label_test) + 1\n",
    "\n",
    "protocol_type_mapping = le_protocol_type.classes_\n",
    "service_mapping = le_service.classes_\n",
    "flag_mapping = le_flag.classes_\n",
    "label_mapping = le_labels.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:49.234246300Z",
     "start_time": "2023-12-24T18:14:49.170681200Z"
    }
   },
   "id": "c229f29f7d4d2c74"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重采样后的数据规模\n",
      "X_train_resampled shape: (269660, 41)\n",
      "labels_train_resampled shape: (269660,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 初始化 SMOTE 对象\n",
    "smote = SMOTE()\n",
    "\n",
    "# 对训练集进行重采样\n",
    "train_data, label_train = smote.fit_resample(train_data, label_train)\n",
    "\n",
    "# 打印重采样后的数据规模\n",
    "print(f'重采样后的数据规模')\n",
    "print(f'X_train_resampled shape: {train_data.shape}')\n",
    "print(f'labels_train_resampled shape: {label_train.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.621572100Z",
     "start_time": "2023-12-24T18:14:49.234246300Z"
    }
   },
   "id": "852f91819d822ef4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import ADASYN\n",
    "# \n",
    "# # 初始化 ADASYN 对象\n",
    "# adasyn = ADASYN()\n",
    "# \n",
    "# # 对训练集进行重采样\n",
    "# train_data, label_train = adasyn.fit_resample(train_data, label_train)\n",
    "# \n",
    "# # 打印重采样后的数据规模\n",
    "# print(f'重采样后的数据规模')\n",
    "# print(f'X_train_resampled shape: {train_data.shape}')\n",
    "# print(f'labels_train_resampled shape: {train_data.shape}')\n",
    "# # 注意：X_test 和 labels_test 不需要重采样"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.668555100Z",
     "start_time": "2023-12-24T18:14:50.621572100Z"
    }
   },
   "id": "afc72f0aefa28b72"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label is Counter({1: 53932, 3: 53932, 2: 53932, 4: 53932, 5: 53932})\n"
     ]
    }
   ],
   "source": [
    "print(f'train_label is {Counter(label_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.668555100Z",
     "start_time": "2023-12-24T18:14:50.637311400Z"
    }
   },
   "id": "8498066fc027f689"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 特征标准化\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard_train_X = scaler.fit_transform(train_data)\n",
    "standard_test_X = scaler.transform(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.848067200Z",
     "start_time": "2023-12-24T18:14:50.668555100Z"
    }
   },
   "id": "79d499973b06c753"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from scipy.stats import pearsonr\n",
    "# import numpy as np\n",
    "# \n",
    "# # 定义计算皮尔森相关系数的函数\n",
    "# def pearsonr_correlation(X, y):\n",
    "#     # 计算每个特征与目标变量的相关性\n",
    "#     correlations = np.array([pearsonr(x, y)[0] for x in X.T])\n",
    "#     return correlations\n",
    "# \n",
    "# # 创建 SelectKBest 实例，选择 k 个最相关的特征\n",
    "# k = 10  # 您可以根据需要设置 k 的值\n",
    "# selector = SelectKBest(score_func=lambda X, y: pearsonr_correlation(X, y), k=k)\n",
    "# \n",
    "# # 对训练数据进行拟合和转换\n",
    "# X_train_selected = selector.fit_transform(standard_train_X, label_train)\n",
    "# \n",
    "# # 对测试数据进行转换\n",
    "# X_test_selected = selector.transform(standard_test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.863758400Z",
     "start_time": "2023-12-24T18:14:50.848067200Z"
    }
   },
   "id": "99874d3b6505f76e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# selector = VarianceThreshold(threshold=1)  # 设置方差的阈值\n",
    "# X_train_selected = selector.fit_transform(standard_train_X)\n",
    "# X_test_selected = selector.transform(standard_test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:50.879388300Z",
     "start_time": "2023-12-24T18:14:50.863758400Z"
    }
   },
   "id": "79dc051a81cc67c2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "FINAL_TRAIN = standard_train_X\n",
    "FINAL_TEST = standard_test_X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:51.854214200Z",
     "start_time": "2023-12-24T18:14:51.822849900Z"
    }
   },
   "id": "f8772933a9438c98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# 初始化SVC模型\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', C=0.5)\n",
    "\n",
    "# 训练模型\n",
    "start = time.time()\n",
    "clf = svc.fit(FINAL_TRAIN, label_train)  # 使用全部数据进行训练\n",
    "print('训练用时：{0}'.format(time.time() - start))\n",
    "# 保存模型（如果需要）\n",
    "# joblib.dump(clf, './model/IDS_model_full_data.m')\n",
    "# print('Model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-24T18:14:51.838526800Z"
    }
   },
   "id": "2e70832859cbe921"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL = clf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c89698906946975c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "# 使用测试集进行预测\n",
    "y_pred = clf.predict(FINAL_TEST)\n",
    "\n",
    "accuracy = np.mean(y_pred == label_test)\n",
    "print(f'accuracy is {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "71339716b2b52cc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 生成混淆矩阵\n",
    "conf_matrix = confusion_matrix(label_test, y_pred)\n",
    "# 获取类别名称（假设 label_mapping 是之前保存的映射）\n",
    "class_names = label_mapping\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "43c68f8b3cde533a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 获取测试集上的决策函数得分\n",
    "y_score = clf.decision_function(FINAL_TEST)\n",
    "\n",
    "# 仅针对 label 列中的唯一值进行二进制化\n",
    "y_test_binarized = label_binarize(label_test, classes=np.unique(label_train))\n",
    "\n",
    "# 计算ROC曲线和ROC面积\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# 绘制所有类别的ROC曲线\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'deeppink', 'navy'])  # 五种颜色\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(class_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f4bf66d751c28350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 计算精度、召回率和F1分数\n",
    "recall = recall_score(label_test, y_pred, average='weighted')\n",
    "precision = precision_score(label_test, y_pred, average='weighted')\n",
    "f1 = f1_score(label_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# 定义MCC分数计算函数\n",
    "def mcc_score(y_true, y_pred, class_label):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tp = cm[class_label, class_label]\n",
    "    tn = np.sum(cm) - np.sum(cm[class_label, :]) - np.sum(cm[:, class_label]) + tp\n",
    "    fp = np.sum(cm[:, class_label]) - tp\n",
    "    fn = np.sum(cm[class_label, :]) - tp\n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "# 计算每个类别的MCC并求平均\n",
    "n_classes = len(np.unique(label_test))  # 确定类别数\n",
    "mcc_scores = [mcc_score(label_test, y_pred, i) for i in range(n_classes)]\n",
    "average_mcc = np.mean(mcc_scores)\n",
    "\n",
    "print(f\"Average MCC: {average_mcc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "de1c389394889413"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 将真实标签转换为 one-hot 编码\n",
    "y_true_bin = label_binarize(label_test, classes=np.unique(label_train))\n",
    "\n",
    "# 确定类别数和类别名称\n",
    "n_classes = y_true_bin.shape[1]\n",
    "class_names = label_mapping  # 确保类别名称正确\n",
    "\n",
    "# 为每个类别绘制PR曲线\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_score[:, i])\n",
    "    auc_score = auc(recall, precision)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.title('Precision-Recall Curve for Class {} (AUC = {:.4f})'.format(class_names[i], auc_score))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9fc65bf8f46f61ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "16c7c5d87bdd263b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "TensorflowPy3.9.16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
