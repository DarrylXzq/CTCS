{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:58:50.617750200Z",
     "start_time": "2023-12-24T10:58:50.607455900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "file_path_train = r\"D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\KDDTrain+.txt\"\n",
    "file_path_test = r\"D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\KDDTest+.txt\"\n",
    "# 定义列名\n",
    "data_columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "                \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "                \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "                \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "                \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "                \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "                \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "                \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "                \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "                \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\", \"difficulty\"]\n",
    "# 加载数据\n",
    "traindata = pd.read_csv(file_path_train, header=None, names=data_columns)\n",
    "testdata = pd.read_csv(file_path_test, header=None, names=data_columns)\n",
    "attack_mapping = {}\n",
    "with open(r'D:\\Download\\zyFile\\Cyberthreat_Cognitive_System\\CTCS_Code\\attack_datasets\\NSL-KDD\\attack_name',\n",
    "          'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(' ')\n",
    "        if len(parts) == 2:\n",
    "            attack, category = parts\n",
    "            attack_mapping[attack] = category\n",
    "# 然后像之前那样使用这个映射字典\n",
    "traindata['label'] = traindata['label'].map(attack_mapping)\n",
    "testdata['label'] = testdata['label'].map(attack_mapping)\n",
    "# 找出只在训练集中出现的 service 类型\n",
    "unique_service_train = set(traindata['service']) - set(testdata['service'])\n",
    "# 删除训练集中存在但测试集中不存在的 service 类型的行\n",
    "traindata = traindata[~traindata['service'].isin(unique_service_train)]\n",
    "# 初始化LabelEncoder\n",
    "le_protocol_type = preprocessing.LabelEncoder()\n",
    "le_service = preprocessing.LabelEncoder()\n",
    "le_flag = preprocessing.LabelEncoder()\n",
    "le_labels = preprocessing.LabelEncoder()\n",
    "\n",
    "# 删除train_data中的difficulty, label列\n",
    "X_train = traindata.drop('label', axis=1)\n",
    "X_train = X_train.drop('difficulty', axis=1)\n",
    "# columns_to_drop = [data_columns[i] for i in [6, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 30]]\n",
    "# X_train = X_train.drop(columns=columns_to_drop)\n",
    "# 提取出训练集中的label标签\n",
    "labels_train = traindata['label']\n",
    "\n",
    "# 删掉测试集的标签项\n",
    "X_test = testdata.drop('label', axis=1)\n",
    "X_test = X_test.drop('difficulty', axis=1)\n",
    "# X_test = X_test.drop(columns=columns_to_drop)\n",
    "labels_test = testdata['label']\n",
    "\n",
    "# 对训练集进行标签编码\n",
    "X_train['protocol_type'] = le_protocol_type.fit_transform(X_train['protocol_type'])\n",
    "X_train['service'] = le_service.fit_transform(X_train['service'])\n",
    "X_train['flag'] = le_flag.fit_transform(X_train['flag'])\n",
    "labels_train = le_labels.fit_transform(labels_train) + 1\n",
    "\n",
    "# 使用相同的编码器对测试集进行标签编码\n",
    "X_test['protocol_type'] = le_protocol_type.transform(X_test['protocol_type'])\n",
    "X_test['service'] = le_service.transform(X_test['service'])\n",
    "X_test['flag'] = le_flag.transform(X_test['flag'])\n",
    "labels_test = le_labels.transform(labels_test) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:58:51.299717300Z",
     "start_time": "2023-12-24T10:58:50.920711800Z"
    }
   },
   "id": "82c4e08935220f52"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y = labels_train\n",
    "T = X_test\n",
    "C = labels_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:58:51.404854600Z",
     "start_time": "2023-12-24T10:58:51.389211100Z"
    }
   },
   "id": "747e7bfe75877900"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:58:52.048412100Z",
     "start_time": "2023-12-24T10:58:51.993940500Z"
    }
   },
   "id": "2314d8c688ad1194"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:58:54.792120500Z",
     "start_time": "2023-12-24T10:58:54.769631900Z"
    }
   },
   "id": "7ed567743e433aad"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23076\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(traindata, trainlabel)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:59:17.569432400Z",
     "start_time": "2023-12-24T10:59:16.087395200Z"
    }
   },
   "id": "b3f1bfa1c71a9c8f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(expected, predicted)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 计算精确率 (precision)\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexpected\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredicted\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 计算召回率 (recall)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m recall \u001B[38;5;241m=\u001B[39m recall_score(expected, predicted)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    212\u001B[0m         )\n\u001B[0;32m    213\u001B[0m     ):\n\u001B[1;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    224\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2131\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   1974\u001B[0m     {\n\u001B[0;32m   1975\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2000\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2001\u001B[0m ):\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \n\u001B[0;32m   2004\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2129\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   2130\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2131\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2132\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2133\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2136\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2138\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2140\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    185\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    189\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1724\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1566\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[0;32m   1567\u001B[0m \n\u001B[0;32m   1568\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1721\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[0;32m   1722\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1723\u001B[0m zero_division_value \u001B[38;5;241m=\u001B[39m _check_zero_division(zero_division)\n\u001B[1;32m-> 1724\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1727\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1518\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1516\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1517\u001B[0m             average_options\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1518\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1519\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m but average=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1520\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoose another average setting, one of \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (y_type, average_options)\n\u001B[0;32m   1521\u001B[0m         )\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1523\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1524\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNote that pos_label (set to \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m) is ignored when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage != \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m). You may use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1528\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1529\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# 假设 `expected` 和 `predicted` 分别是真实标签和模型预测标签\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "# 计算精确率 (precision)\n",
    "precision = precision_score(expected, predicted)\n",
    "# 计算召回率 (recall)\n",
    "recall = recall_score(expected, predicted)\n",
    "# 计算F1分数 (f1-score)\n",
    "f1 = f1_score(expected, predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:59:25.182366800Z",
     "start_time": "2023-12-24T10:59:24.958025500Z"
    }
   },
   "id": "24f073ed3cf59498"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "[[5566 1184  579  307    0]\n",
      " [ 132 9425  146    6    2]\n",
      " [ 446  611 1364    0    0]\n",
      " [   4 2233  113  224    2]\n",
      " [  53   83   51    3   10]]\n",
      "0.729\n",
      "0.971\n",
      "Accuracy\n",
      "0.638\n",
      "precision\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39maccuracy)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\u001B[43mprecision\u001B[49m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39mrecall)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T10:59:42.865905Z",
     "start_time": "2023-12-24T10:59:40.652035600Z"
    }
   },
   "id": "f7e5873a414a17c5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6099 1530    7    0    0]\n",
      " [ 565 9073   72    0    1]\n",
      " [1427  849  145    0    0]\n",
      " [ 255 2314    7    0    0]\n",
      " [  36  113   51    0    0]]\n",
      "0.799\n",
      "0.934\n",
      "Accuracy\n",
      "0.638\n",
      "precision\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39maccuracy)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\u001B[43mprecision\u001B[49m)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39mrecall)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:00:28.176667800Z",
     "start_time": "2023-12-24T10:59:58.958814Z"
    }
   },
   "id": "1d4f3f20089f5186"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af54c2fecc5a87db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
