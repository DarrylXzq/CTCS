{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:00:24.280670400Z",
     "start_time": "2023-11-22T03:00:24.235162900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('kddtrain.csv', header=None)\n",
    "testdata = pd.read_csv('kddtest.csv', header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:00:25.562883600Z",
     "start_time": "2023-11-22T03:00:25.165665900Z"
    }
   },
   "id": "82c4e08935220f52"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,0]\n",
    "C = testdata.iloc[:,0]\n",
    "T = testdata.iloc[:,1:42]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:00:26.711381900Z",
     "start_time": "2023-11-22T03:00:26.672956700Z"
    }
   },
   "id": "747e7bfe75877900"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'tcp'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m scaler \u001B[38;5;241m=\u001B[39m \u001B[43mNormalizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m trainX \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m      3\u001B[0m scaler \u001B[38;5;241m=\u001B[39m Normalizer()\u001B[38;5;241m.\u001B[39mfit(T)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1989\u001B[0m, in \u001B[0;36mNormalizer.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1969\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1970\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1971\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Only validates estimator's parameters.\u001B[39;00m\n\u001B[0;32m   1972\u001B[0m \n\u001B[0;32m   1973\u001B[0m \u001B[38;5;124;03m    This method allows to: (i) validate the estimator's parameters and\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1987\u001B[0m \u001B[38;5;124;03m        Fitted transformer.\u001B[39;00m\n\u001B[0;32m   1988\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1989\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1990\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:605\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    603\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 605\u001B[0m     out \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[0;32m    607\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    913\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 915\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    917\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    918\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    919\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    378\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 380\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:2084\u001B[0m, in \u001B[0;36mNDFrame.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   2082\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: npt\u001B[38;5;241m.\u001B[39mDTypeLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m   2083\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 2084\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2086\u001B[0m         astype_is_view(values\u001B[38;5;241m.\u001B[39mdtype, arr\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m   2087\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write()\n\u001B[0;32m   2088\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mis_single_block\n\u001B[0;32m   2089\u001B[0m     ):\n\u001B[0;32m   2090\u001B[0m         \u001B[38;5;66;03m# Check if both conversions can be done without a copy\u001B[39;00m\n\u001B[0;32m   2091\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m astype_is_view(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtypes\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m], values\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m astype_is_view(\n\u001B[0;32m   2092\u001B[0m             values\u001B[38;5;241m.\u001B[39mdtype, arr\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m   2093\u001B[0m         ):\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'tcp'"
     ]
    }
   ],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:00:28.153405100Z",
     "start_time": "2023-11-22T03:00:27.373641600Z"
    }
   },
   "id": "2314d8c688ad1194"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed567743e433aad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(traindata, trainlabel)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3f1bfa1c71a9c8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 假设 `expected` 和 `predicted` 分别是真实标签和模型预测标签\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "# 计算精确率 (precision)\n",
    "precision = precision_score(expected, predicted)\n",
    "# 计算召回率 (recall)\n",
    "recall = recall_score(expected, predicted)\n",
    "# 计算F1分数 (f1-score)\n",
    "f1 = f1_score(expected, predicted)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24f073ed3cf59498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e5873a414a17c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4f3f20089f5186"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
